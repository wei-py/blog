---
title: 20251219
date: 2025-12-19
category: daily
tags:
  - blog
---

Mac Mini M4 24GB **完全够用**，而且效果会很好！Apple Silicon 对这类任务特别友好。

## 针对 Mac Mini M4 的最佳方案

### 方案一：最简单高效（推荐）

**1. Whisper (Apple Silicon 优化版)**
```bash
# 安装 whisper-cpp（专为 Apple Silicon 优化）
brew install whisper-cpp

# 或者用 Python 版本
pip install openai-whisper

# 使用（M4 用 large-v3 没问题）
whisper video.mp4 --model large-v3 --language ja --task translate
```

**性能预估**：
- 1小时视频识别：约 8-12 分钟
- 24GB 内存运行 large-v3 绰绰有余

---

**2. 翻译 - Ollama（原生支持 Apple Silicon）**
```bash
# 安装
brew install ollama

# 启动服务
ollama serve

# 下载中文模型（推荐）
ollama pull qwen2.5:14b     # 中文能力最强，8GB 模型
ollama pull deepseek-r1:14b # 推理能力好，适合技术内容

# 使用
ollama run qwen2.5:14b "翻译优化以下字幕..."
```

**M4 优势**：
- 统一内存架构，24GB 全部可用
- qwen2.5:14b 在 M4 上流畅运行
- 推理速度约 30-50 tokens/s

---

**3. 语音合成 - 两个选择**

**选项A：Piper TTS（轻量）**
```bash
# 下载预编译版本
# https://github.com/rhasspy/piper/releases

# 使用中文模型
echo "翻译文本" | ./piper --model zh_CN-huayan-medium --output_file output.wav
```

**选项B：macOS 系统自带（最简单）**
```bash
# 直接用 macOS say 命令
say -v Ting-Ting "这是翻译后的文本" -o output.aiff
```

---

### 方案二：一键式工具（最省心）

**VideoLingo（支持 Mac）**
```bash
# 安装
git clone https://github.com/Huanshere/VideoLingo
cd VideoLingo
pip install -r requirements.txt

# 配置文件设置：
# - Whisper: large-v3
# - LLM: Ollama (qwen2.5:14b)
# - TTS: 系统自带或 Azure

# 运行
python main.py
```

**优势**：
- Web UI 操作简单
- 自动处理字幕时间轴
- 支持术语词典（对技术视频重要）

---

### 方案三：音色克隆（进阶）

如果想保留原日语说话人音色：

**Bark（Apple Silicon 友好）**
```bash
pip install bark

# Python 代码
from bark import SAMPLE_RATE, generate_audio, preload_models
preload_models()
audio_array = generate_audio("翻译文本", history_prompt="v2/zh_speaker_6")
```

---

## 实际性能预估（Mac Mini M4）

| 任务 | 1小时视频耗时 | 内存占用 |
|------|--------------|----------|
| Whisper large-v3 | 8-12分钟 | ~6GB |
| Ollama qwen2.5:14b | 5-8分钟 | ~9GB |
| TTS 合成 | 3-5分钟 | ~2GB |
| **总计** | **约20-30分钟** | **峰值15GB** |

---

## 推荐的完整工作流

```bash
# 1. 安装依赖
brew install ollama ffmpeg
pip install openai-whisper

# 2. 启动 Ollama
ollama serve &
ollama pull qwen2.5:14b

# 3. 创建处理脚本
```

我可以给你写一个自动化脚本，把整个流程串起来。需要吗？

**关键提示**：
- ✅ M4 的神经引擎会加速 Whisper
- ✅ 24GB 统一内存足够同时运行所有模型
- ✅ 可以边识别边翻译，提高效率
- ⚠️ 建议用有线网络下载模型（Ollama 模型约 8-14GB）

需要我提供具体的部署命令或脚本吗？